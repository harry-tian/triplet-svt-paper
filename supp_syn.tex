%!TEX root = main.tex 

% \clearpage
\section{Synthetic experiment results}
\label{sec:supp_syn}

\subsection{Hyperparameters}
We use different controlling strength between classification and human judgment prediction, including $\lambda$s at 0.2, 0.5, and 0.8, and discuss the effect of $\lambda$ in the next section. In contrast to the experiments on BM, we observe that \mtl with 512-dimension embedding shows overall better performance than \mtl with 50-dimension embedding and show results for the latter in the next section.
We use the Adam optimizer \cite{kingma2014adam} with learning rate $1e-4$.
We use a training batch size of $40$ for triplet prediction, and $30$ for classification.


\subsection{Additional results}

\paragraph{Classification and triplet accuracy.} Table~\ref{tab:wv-square-clf-trip} shows how tuning $\lambda$ affects \mtl 's classification and triplet accuracy. Higher $\lambda$ drives \mtl to behave more simlar to \resn while lower \mtl is more similar to \tn.

\input{tables/supp/clf_triplet_acc.tex}
\paragraph{Experiment results on VW with confidence intervals.}
Table~\ref{tab:table1-ci} presents results on VW with \mtl $\lambda=0.5$. This is is simply Table 1 in the main paper with 0.95 confidence intervals.

\input{tables/supp/wv_square_filtered_l=0.5_ci.tex}

\paragraph{Results for different $\lambda$.}
In Table~\ref{tab:wv_square_filtered_l=0.2} and Table~\ref{tab:wv_square_filtered_l=0.8} we show experiment results with \mtl using $\lambda=0.2$ and $\lambda=0.8$. We do not observe a clear trend between $\lambda$ and evaluation metric performances. In the main paper we present \mtl with $\lambda=0.5$ as it shows best overall performance.

\input{tables/supp/wv_square_filtered_l=0.2_ci.tex}

\input{tables/supp/wv_square_filtered_l=0.8_ci.tex}


\paragraph{Results for 50-dimension embedding.} Table~\ref{tab:wv_square_filtered_l=0.5_d=50} shows results with all models outputing a 50-dimension embedding. Similar to $\lambda$, the trend between embedding dimension and our evaluation metrics is not clear.

\input{tables/supp/wv_square_filtered_l=0.5_d=50.tex}


\paragraph{Results for unfiltered \mtl.} 
In table~\ref{tab:wv_square_unfiltered_l=0.5} we show results on \mtl with $\lambda=0.5$ using unfiltered triplets. An unfiltered \mtl performs much worse in NINO decision support, as also shown by Figure 3 in the main paper.
We also show in ~\figref{fig:filter-h2h} more clear effects of filtering on H2H performance. We conclude that filtered \mtl leads to worse H2H performance but much better decision support performance.

\input{tables/supp/wv_square_unfiltered_l=0.5_ci.tex}


\begin{table}[t]
    \begin{minipage}[b]{\textwidth}
      \centering
      \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]{figures/supp/wv_square_NI-h2h_filter.pdf}
        \end{subfigure}
        \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]{figures/supp/wv_square_NO-h2h_filter.pdf}
        \end{subfigure}
        \captionof{figure}{H2H performance on VW,  MTL with filtered and unfiltered triplets.}
        \label{fig:filter-h2h}
    \end{minipage}
  \end{table}
  

\paragraph{The effect of noise on unfiltered \mtl} As ~\figref{fig:noise-unfiltered} shows, \mtl trained on unfiltered triplets is more vulnerable to noise perturbation. H2H and decision support performance is overall worse and decreases much faster than that of filtered \mtl (Figure 4 in the main paper).

\begin{table}[t]
  \begin{minipage}[b]{\textwidth}
    \centering
    \begin{subfigure}[b]{0.32\textwidth}
      \includegraphics[width=\textwidth]{figures/supp/wv_square_noise_unfiltered_h2h.pdf}
      \end{subfigure}
      \begin{subfigure}[b]{0.32\textwidth}
        \includegraphics[width=\textwidth]{figures/supp/wv_square_noise_unfiltered_NINO.pdf}
      \end{subfigure}
      \begin{subfigure}[b]{0.32\textwidth}
        \includegraphics[width=\textwidth]{figures/supp/wv_square_noise_unfiltered_NIFO.pdf}
      \end{subfigure}
      \captionof{figure}{Results on VW with varying noise levels. \mtl uses unfiltered triplets}
      \label{fig:noise-unfiltered}
  \end{minipage}
\end{table}

\paragraph{Additional details on weight generation.}
We generate alignment scores by searching through weight combinations of the simulated human visual similarity metrics. We search the weights in powers of 2, from 0 to $2^{10}$, producing a sparse distribution of alignments (~\figref{fig:align-hist}). Increasing search range to powers of 10 produces smoother distribution, but the weights are also more extreme and unrealistic. We note that the alignment distribution may vary across different datasets. In our experiments we choose weights and alignments to be as representative to the distribution as possible.

\begin{table}[t]
    \centering
    \begin{subfigure}[b]{0.49\textwidth}
    \includegraphics[width=\textwidth]{figures/supp/weights.png}
    \end{subfigure}
    \captionof{figure}{Histogram of alignments generated by searching informative weights in powers of 2.}
    \label{fig:align-hist}
\end{table}





\subsection{Additional decision boundaries}

We create a linear decision boundary on VW without altering the dataset (\figref{fig:linear-dist}). We find the results are overall similar to the original VW data.
 
% \begin{table}[t]
%     \centering
%   \begin{minipage}[b]{0.31\textwidth}
%     \includegraphics[width=\textwidth]{figures/supp/linear_dist.png}
%     \captionof{figure}{VW dataset with a linear decision boundary.}
%     \label{fig:linear-dist}
%   \end{minipage}
%   \hfill
%   \begin{minipage}[b]{0.63\textwidth}
%     \input{tables/supp/wv_squarelin_clf_triplet_acc.tex}
%   \end{minipage}
% \end{table}

% \paragraph{Classification and triplet accuracy.} Table~\ref{tab:lin-clf} shows classification and
% triplet accuracy of tuning $\lambda$, showing a similar trend to the previous experiment.

% \paragraph{H2H and decision support results}

% In Table~\ref{tab:wv_lin_filtered_l=0.5} we present results with the best set of hyperparameter: filtered triplets, 512-dimension embedding, $\lambda=0.5$. We show results for $\lambda=0.2$ in Table 13 and $\lambda=0.8$ in Table 14. We also show results with 50-dimension \mtl in Table 15 and unfiltered \mtl in Table 16. 

% Similar to the experiment on VW square decision boundary, we see no clear relation between $\lambda$, embedding dimension and our evaluation metrics. Table 16 again shows that filtered \mtl leads to better decision support but worse H2H.

% \input{tables/supp/wv_squarelin_filtered_l=0.5_ci.tex}

% \input{tables/supp/wv_squarelin_filtered_l=0.2_ci.tex}

% \input{tables/supp/wv_squarelin_filtered_l=0.8_ci.tex}

% \input{tables/supp/wv_squarelin_filtered_l=0.5_d=50.tex}

% \input{tables/supp/wv_squarelin_unfiltered_l=0.5_ci.tex}

% \paragraph{The effect of perturbations} Similar to previous results, adding noise harms H2H and decision support performance with unfiltered \mtl more so than filtered (~\figref{fig:lin-noise-filtered}, ~\figref{fig:lin-noise-unfiltered}). ~\figref{fig:lin-num} shows H2H and decision support performance with decreasing number of triplets; similar to results in the main paper, H2H decreases more rapidly.

% \begin{table}[t]
%   \begin{minipage}[b]{\textwidth}
%     \centering
%     \begin{subfigure}[b]{0.32\textwidth}
%       \includegraphics[width=\textwidth]{figures/supp/wv_squarelin_noise_filtered_h2h.pdf}
%       \end{subfigure}
%       \begin{subfigure}[b]{0.32\textwidth}
%         \includegraphics[width=\textwidth]{figures/supp/wv_squarelin_noise_filtered_NINO.pdf}
%       \end{subfigure}
%       \begin{subfigure}[b]{0.32\textwidth}
%         \includegraphics[width=\textwidth]{figures/supp/wv_squarelin_noise_filtered_NIFO.pdf}
%       \end{subfigure}
%       \captionof{figure}{Results on VW linear decision boundary data with varying noise levels. \mtl uses filtered triplets.}
%       \label{fig:lin-noise-filtered}
%   \end{minipage}
% \end{table}


% \begin{table}[t]
%   \begin{minipage}[b]{\textwidth}
%     \centering
%     \begin{subfigure}[b]{0.32\textwidth}
%       \includegraphics[width=\textwidth]{figures/supp/wv_squarelin_noise_unfiltered_h2h.pdf}
%       \end{subfigure}
%       \begin{subfigure}[b]{0.32\textwidth}
%         \includegraphics[width=\textwidth]{figures/supp/wv_squarelin_noise_unfiltered_NINO.pdf}
%       \end{subfigure}
%       \begin{subfigure}[b]{0.32\textwidth}
%         \includegraphics[width=\textwidth]{figures/supp/wv_squarelin_noise_unfiltered_NIFO.pdf}
%       \end{subfigure}
%       \captionof{figure}{Results on VW linear decision boundary data with varying noise levels. \mtl uses unfiltered triplets.}
%       \label{fig:lin-noise-unfiltered}
%   \end{minipage}
% \end{table}



% \begin{table}[t]
%   \begin{minipage}[b]{\textwidth}
%     \centering
%     \begin{subfigure}[b]{0.32\textwidth}
%       \includegraphics[width=\textwidth]{figures/supp/wv_squarelin_num_h2h.pdf}
%       \end{subfigure}
%       \begin{subfigure}[b]{0.32\textwidth}
%         \includegraphics[width=\textwidth]{figures/supp/wv_squarelin_num_NINO.pdf}
%       \end{subfigure}
%       \begin{subfigure}[b]{0.32\textwidth}
%         \includegraphics[width=\textwidth]{figures/supp/wv_squarelin_num_NIFO.pdf}
%       \end{subfigure}
%       \captionof{figure}{Results on VW linear decision boundary data with varying number of triplets. \mtl uses filtered triplets.}
%       \label{fig:lin-num}
%   \end{minipage}
% \end{table}