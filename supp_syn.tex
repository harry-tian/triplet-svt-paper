%!TEX root = main.tex 

% \clearpage
\section{Synthetic experiments}
\label{sec:supp_syn}

In addition to BM, we also experiment with synthetic datasets as we can tune more variables and better understand the strengths and limitations of our method. Using simulated human similarity metrics, we control and vary the level of disagreement between the classification groundtruth and the human's knowledge.

\subsection{Synthetic dataset and simulated humans}

\begin{figure}[t]
  \centering
  \includegraphics[width=\textwidth]{figures/wv/wv.pdf}
   \caption{VW dataset. (a) shows the non-linear decision boundary of the dataset determined by two features: the head and the body size of the fictional insects. The Weevil has a mid-sized body and mid-sized head, while the Vespula does not. Tail length and texture are two non-informative features.}
   \label{fig:vw}
  \end{figure}

% \begin{table}[t]
%     \centering
%     \begin{subfigure}[b]{0.49\textwidth}
%     \includegraphics[width=\textwidth]{figures/supp/weights.png}
%     \end{subfigure}
%     \captionof{figure}{Histogram of alignments generated by searching informative weights in powers of 2.}
%     \label{fig:align-hist}
% \end{table}

We use the synthetic dataset ``Vespula vs Weevil'' (VW) from \citet{chen2018near}.
It is a binary image classification dataset of two fictional species of insects.
Each example contains four features, two of them---head and body size---are predictive of the label, the other two---tail length and texture---are completely non-predictive.
We generate 2000 images and randomly split the dataset into training, validation, and testing sets in a 60\%:20\%:20\% ratio.
The labels are determined by various synthetic decision boundaries, such as the one shown in \figref{fig:vw}a.
We report the results for \figref{fig:vw}a, a double-square decision boundary, in section C.2 and results for a linear decision boundary data in section C.3.


To generate triplets data, we simulate human visual similarity metrics by adding weights to each feature in Euclidean distance computation.
By changing the weight on each feature, we can control the level of disagreement between simulated human and the groundtruth.
All procedures that involve humans (e.g., triplet data collection and evaluation) are replaced by the simulated human in this set of experiments.

To quantify the disagreement, we use 1-NN classification accuracy following the simulated human similarity metric; we refer to it as the alignment score.
The alignment score ranges from 50\% (setting the informative features' weights to 0 and distractor weights to 1) to 100\% (setting all weights to 1).
We generate alignment scores by searching through weight combinations of the simulated human visual similarity metrics. We search the weights in powers of 2, from 0 to $2^{10}$, producing a sparse distribution of alignments (~\figref{fig:align-hist}). Increasing search range to powers of 10 produces smoother distribution, but the weights are also more extreme and unrealistic. We note that the alignment distribution may vary across different datasets. In our experiments we choose weights and alignments to be as representative to the distribution as possible. In each alignment setting, we generate 40,000 triplets using the simulated humans similarity metric.



\subsection{Double-square decision boundary experiment results}


\subsubsection{Hyperparameters} 
We train all models with a large emebdding dimension of 512 and a small emebdding dimension of 50 and observe that a 512-dimension embeddings is preferable based on most metrics. We also train \mtl on a filtered vs. unfiltered triplets as well as with different values $\lambda$ at 0.2, 0.5, and 0.8. 
For our main results, we report the performance with $\lambda=0.5$ and filtered triplets.
We will discuss the effect of filtering later in this section.  In contrast to the experiments on BM, we observe that \mtl with 512-dimension embedding shows overall better performance than \mtl with 50-dimension embedding and show results for the latter in the next section.
We use the Adam optimizer \cite{kingma2014adam} with learning rate $1e-4$.
We use a training batch size of $40$ for triplet prediction, and $30$ for classification.


\subsubsection{Results}

\input{tables/supp/clf_triplet_acc.tex}
\input{tables/supp/wv_square_filtered_l=0.5_ci.tex}


We compare \mtl, \resn, \tn on classification accuracy, triplet accuracy, and decision support performance for simulated humans. 
Table~\ref{tab:wv-square-clf-trip} shows how tuning $\lambda$ affects \mtl 's classification and triplet accuracy. Higher $\lambda$ drives \mtl to behave more simlar to \resn while lower \mtl is more similar to \tn.


\paragraph{Experiment results on VW with confidence intervals.}
Table~\ref{tab:table1-ci} presents results on VW with \mtl $\lambda=0.5$. This is is simply Table 1 in the main paper with 0.95 confidence intervals.


\paragraph{Results for different $\lambda$.}
In Table~\ref{tab:wv_square_filtered_l=0.2} and Table~\ref{tab:wv_square_filtered_l=0.8} we show experiment results with \mtl using $\lambda=0.2$ and $\lambda=0.8$. We do not observe a clear trend between $\lambda$ and evaluation metric performances. In the main paper we present \mtl with $\lambda=0.5$ as it shows best overall performance.

\input{tables/supp/wv_square_filtered_l=0.2_ci.tex}

\input{tables/supp/wv_square_filtered_l=0.8_ci.tex}


\paragraph{Results for 50-dimension embedding.} Table~\ref{tab:wv_square_filtered_l=0.5_d=50} shows results with all models outputing a 50-dimension embedding. Similar to $\lambda$, the trend between embedding dimension and our evaluation metrics is not clear.

\input{tables/supp/wv_square_filtered_l=0.5_d=50.tex}


\paragraph{Results for unfiltered \mtl.} 
In table~\ref{tab:wv_square_unfiltered_l=0.5} we show results on \mtl with $\lambda=0.5$ using unfiltered triplets. An unfiltered \mtl performs much worse in NINO decision support, as also shown by Figure 3 in the main paper.
We also show in ~\figref{fig:filter-h2h} more clear effects of filtering on H2H performance. We conclude that filtered \mtl leads to worse H2H performance but much better decision support performance.

\input{tables/supp/wv_square_unfiltered_l=0.5_ci.tex}


\begin{table}[t]
    \begin{minipage}[b]{\textwidth}
      \centering
      \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]{figures/supp/wv_square_NI-h2h_filter.pdf}
        \end{subfigure}
        \begin{subfigure}[b]{0.49\textwidth}
        \includegraphics[width=\textwidth]{figures/supp/wv_square_NO-h2h_filter.pdf}
        \end{subfigure}
        \captionof{figure}{H2H performance on VW,  MTL with filtered and unfiltered triplets.}
        \label{fig:filter-h2h}
    \end{minipage}
  \end{table}
  

\paragraph{The effect of noise on unfiltered \mtl} As ~\figref{fig:noise-unfiltered} shows, \mtl trained on unfiltered triplets is more vulnerable to noise perturbation. H2H and decision support performance is overall worse and decreases much faster than that of filtered \mtl (Figure 4 in the main paper).

\begin{table}[t]
  \begin{minipage}[b]{\textwidth}
    \centering
    \begin{subfigure}[b]{0.32\textwidth}
      \includegraphics[width=\textwidth]{figures/supp/wv_square_noise_unfiltered_h2h.pdf}
      \end{subfigure}
      \begin{subfigure}[b]{0.32\textwidth}
        \includegraphics[width=\textwidth]{figures/supp/wv_square_noise_unfiltered_NINO.pdf}
      \end{subfigure}
      \begin{subfigure}[b]{0.32\textwidth}
        \includegraphics[width=\textwidth]{figures/supp/wv_square_noise_unfiltered_NIFO.pdf}
      \end{subfigure}
      \captionof{figure}{Results on VW with varying noise levels. \mtl uses unfiltered triplets}
      \label{fig:noise-unfiltered}
  \end{minipage}
\end{table}



In synthetic experiments, \mtl achieves the same perfect classification accuracy as \resn (100\%), and a triplet accuracy of 0.968 which is comparable to \tn.
This shows that \mtl indeed learns both the classification task and human similarity prediction task.
We next present the evaluation on case-based decision support with synthetic humans, which is the key goal of this work.

% We start by discussing results with our best \mtl model in different case-based decision support scenarios, and then discuss the effect of different parameter choices. 
% We evaluate \mtl using H2H comparison with \resn as report the results of using NI and NO as justifications.
% We also present NN decision support and NIFO decision support across different alignment settings in comparison to \resn and \tn.

\para{\mtl significantly outperforms \resn in H2H.} 
% \chenhao{replace the header with the main takeaway.}
Our synthetic humans prefer \mtl over \resn by a large margin as justifications for both nearest in-class examples and nearest out-of-class examples, indicating the NIs and NOs selected from the \mtl representations are more aligned with the synthetic humans than \tn. % There is no clear pattern between H2H performance and alignment, suggesting that \mtl is able to learn a wide range of human similarity. 
% Also note that 
For NI H2H, the preference towards \mtl declines as the alignment improves, because if alignment between human similarity and classification increases, \resn can capture human similarity as a byproduct of classification.
Also, NO H2H is higher than NI H2H, suggesting \resn learns a better representation within each class compared to between classes. 
% \harry{I want to say something like "\resn is likely to produce embeddings with class-defined clusters, making NI easier than NO". not sure if that makes sense}.

% \mtl learns a more human-compatible embedding space.


% \cc{from important results to unimportant results}

\para{\mtl provides the best decision support.} 
% \harry{should we bold the highest numbers in tbale1?}
Table \ref{tab:main-results} shows that \mtl achieves the highest NINO and NIFO decision support scores in all alignments. %This further emphasizes that the \mtl representation has high classificaiton ability and human similarity alignment. 
% \harry{TODO: more discussion here.}
In NINO decision support, \resn consistently outperforms \tn, highlighting that representation solely learned for metric learning is ineffective for decision support.
For all models, the decision support performance improves as the alignments increases, suggesting that decision support is easier when human similarity judgement is aligned with the classification task.
\resn and \tn are more comparable in NIFO, while \mtl consistently shows 100\%.
The fact that \resn shows comparable performance between NINO and NIFO further confirms that \resn does not capture meaning similarity for examples from two different classes.

% both \resn and \tn see decerased decision support performance in varying settings. \resn sees good NINO performance but fails at the easier NIFO task; its NINO and NIFO scores are similar, likely because \resn embeddings do not differentiate NO and FO. \tn is good at NIFO but significantly worse at NINO, suggesting that NINO may be a task that benefits from strong classification performance and high human alignment. 

\para{Filtering triplets leads to better decision support}. \figref{fig:filter} shows that filtering class-inconsistent triplets improves \mtl's decision support performance across all alignments. Further details in the supplementary material show that filtering slightly hurts direct comparison performance. 
This suggests that in terms of decision support, the benefit of filtering out human noise may overweigh the loss of some similarity judgment.

% \para{Alignment matches with NINO decision support.} For all models, there is a linear trend between alignment and NINO decision support performance. 


\input{tables/main-results.tex}

\begin{table}[t]
  \begin{minipage}[b]{0.38\textwidth}
    \centering
    \includegraphics[width=\textwidth]{figures/filtered_NINO_err.pdf}
    % \begin{subfigure}[b]{0.495\textwidth}
    % \includegraphics[width=\textwidth]{figures/filtered_h2h.pdf}
    % \caption{H2H with \resn}
    % \end{subfigure}
    \captionof{figure}{NINO decision support on \mtl with filtered and unfiltered triplets. Filtered triplets leads to greatly improved performance. }
    % \cc{legend is wrong?}}
    \label{fig:filter}
  \end{minipage}
  \hfill
  \begin{minipage}[b]{0.6\textwidth}
    \centering
    \begin{subfigure}[b]{0.32\textwidth}
      \includegraphics[width=\textwidth]{figures/noise_h2h_v1.pdf}
      % \caption{NI H2H}
      \end{subfigure}
      \begin{subfigure}[b]{0.32\textwidth}
      \includegraphics[width=\textwidth]{figures/noise_NINO_v1.pdf}
      % \caption{NINO}
      \end{subfigure}
      \begin{subfigure}[b]{0.32\textwidth}
      \includegraphics[width=\textwidth]{figures/noise_NIFO.pdf}
      % \caption{NIFO}
      \end{subfigure}
      \captionof{figure}{Noise hurts direct comparison more than decision support.}
      \label{fig:noise}
      \begin{subfigure}[b]{0.32\textwidth}
        \includegraphics[width=\textwidth]{figures/num_h2h_v1.pdf}
        % \caption{H2H with \resn}
        \end{subfigure}
        \begin{subfigure}[b]{0.32\textwidth}
        \includegraphics[width=\textwidth]{figures/num_NINO_v1.pdf}
        % \caption{NINO}
        \end{subfigure}
        \begin{subfigure}[b]{0.32\textwidth}
        \includegraphics[width=\textwidth]{figures/num_NIFO_v1.pdf}
        % \caption{NIFO}
        \end{subfigure}
        \caption{\mtl performance declines as the number of triplets decreases, but shows strong NIFO decision support accuracy even with very few triplets.}
        % \harry{TODO: update to predicted label}}
        \label{fig:vary-num}
  \end{minipage}
\end{table}


\para{The effect of noise in triplets.}
To test the limitations of \mtl, we perturb human judgment by adding noise to triplets. 
We add noise to triplets by randomly flipping the similarity judgement (i.e., a triplet $(x^r, x^+, x^-)$ becomes $(x^r, x^-, x^+)$) with probability $p$.
As shown in \figref{fig:noise}, direct comparison results decreases linearly as noise increases, decision support performance does not start decreasing util $p=0.5$. 
This is not as surprising for two reasons. First, since VW is a binary dataset, half of the triplets are ones where $x^+, x^-$ belong to the same class; 
flipping these triplets does not have a significant effect on the generated embeddings. 
More importantly, filtering greatly reduces the adversarial effect of adding noise, highlighting the importance of filtering. 
In comparison, \tn drops linearly in NINO, so do \mtl with unfiltered triplets (see supplementary materials).

% \begin{figure}[ht]
%   \centering
%   \begin{subfigure}[b]{0.329\textwidth}
%   \includegraphics[width=\textwidth]{figures/noise_h2h.pdf}
%   \caption{NI H2H with \resn}
%   \end{subfigure}
%   \begin{subfigure}[b]{0.329\textwidth}
%   \includegraphics[width=\textwidth]{figures/noise_NINO.pdf}
%   \caption{NINO decision support}
%   \end{subfigure}
%   \begin{subfigure}[b]{0.329\textwidth}
%   \includegraphics[width=\textwidth]{figures/noise_NIFO.pdf}
%   \caption{NIFO decision support}
%   \end{subfigure}
%   \caption{Results on adding noise to triplets. Noise hurts direct comparison more than decision support. \harry{TODO: update to predicted label}}
%   \label{fig:noise}
% \end{figure}


% \begin{figure}[ht]
%   \centering
%   \begin{subfigure}[b]{0.329\textwidth}
%   \includegraphics[width=\textwidth]{figures/noise_h2h_unfiltered.pdf}
%   \caption{NI H2H with \resn}
%   \end{subfigure}
%   \begin{subfigure}[b]{0.329\textwidth}
%   \includegraphics[width=\textwidth]{figures/noise_NINO_unfiltered.pdf}
%   \caption{NINO decision support}
%   \end{subfigure}
%   \begin{subfigure}[b]{0.329\textwidth}
%   \includegraphics[width=\textwidth]{figures/noise_NIFO_unfiltered.pdf}
%   \caption{NIFO decision support}
%   \end{subfigure}
%   \caption{Results on adding noise to unfiltered triplets. The impact of noise is much more prominent when using unfiltered triples.}
%   \label{fig:noise_unfiltered}
% \end{figure}

% \begin{figure}[ht]
%   \centering
%   \begin{subfigure}[b]{0.329\textwidth}
%   \includegraphics[width=\textwidth]{figures/num_h2h.pdf}
%   \caption{H2H with \resn}
%   \end{subfigure}
%   \begin{subfigure}[b]{0.329\textwidth}
%   \includegraphics[width=\textwidth]{figures/num_NINO.pdf}
%   \caption{NINO}
%   \end{subfigure}
%   \begin{subfigure}[b]{0.329\textwidth}
%   \includegraphics[width=\textwidth]{figures/num_NIFO.pdf}
%   \caption{NIFO}
%   \end{subfigure}
%   \caption{Results on decreasing the number of triplets. \mtl shows decent performance with very few triplets.\harry{TODO: update to predicted label}}
%   \label{fig:vary-num}
% \end{figure}

\para{Number of triplets} We examine the effect of the number of triplets. We decrease number of triplets by powers of 2 
and find that H2H preference towards \mtl indeed declines as \mtl representation is less human-compatible with fewer training data.
As for decision support, in NINO, \mtl declines and eventually approaches \resn except the outlier at end, while in NIFO, \mtl is able to stay 100\% even as the number of triplets declines. 





\subsection{Additional decision boundaries}

We create a linear decision boundary on VW without altering the dataset (\figref{fig:linear-dist}). We find the results are overall similar to the original VW data.
 
\begin{table}[t]
    \centering
  \begin{subfigure}[b]{0.31\textwidth}
    \includegraphics[width=\textwidth]{figures/supp/linear_dist.png}
    \caption{VW dataset with a linear decision boundary.}
    \label{fig:linear-dist}
  \end{subfigure}
\end{table}

% \hfill
% \begin{minipage}[b]{0.63\textwidth}
%   \input{tables/supp/wv_squarelin_clf_triplet_acc.tex}
% \end{minipage}
% \paragraph{Classification and triplet accuracy.} Table~\ref{tab:lin-clf} shows classification and
% triplet accuracy of tuning $\lambda$, showing a similar trend to the previous experiment.

% \paragraph{H2H and decision support results}

% In Table~\ref{tab:wv_lin_filtered_l=0.5} we present results with the best set of hyperparameter: filtered triplets, 512-dimension embedding, $\lambda=0.5$. We show results for $\lambda=0.2$ in Table 13 and $\lambda=0.8$ in Table 14. We also show results with 50-dimension \mtl in Table 15 and unfiltered \mtl in Table 16. 

% Similar to the experiment on VW square decision boundary, we see no clear relation between $\lambda$, embedding dimension and our evaluation metrics. Table 16 again shows that filtered \mtl leads to better decision support but worse H2H.

% \input{tables/supp/wv_squarelin_filtered_l=0.5_ci.tex}

% \input{tables/supp/wv_squarelin_filtered_l=0.2_ci.tex}

% \input{tables/supp/wv_squarelin_filtered_l=0.8_ci.tex}

% \input{tables/supp/wv_squarelin_filtered_l=0.5_d=50.tex}

% \input{tables/supp/wv_squarelin_unfiltered_l=0.5_ci.tex}

% \paragraph{The effect of perturbations} Similar to previous results, adding noise harms H2H and decision support performance with unfiltered \mtl more so than filtered (~\figref{fig:lin-noise-filtered}, ~\figref{fig:lin-noise-unfiltered}). ~\figref{fig:lin-num} shows H2H and decision support performance with decreasing number of triplets; similar to results in the main paper, H2H decreases more rapidly.

% \begin{table}[t]
%   \begin{minipage}[b]{\textwidth}
%     \centering
%     \begin{subfigure}[b]{0.32\textwidth}
%       \includegraphics[width=\textwidth]{figures/supp/wv_squarelin_noise_filtered_h2h.pdf}
%       \end{subfigure}
%       \begin{subfigure}[b]{0.32\textwidth}
%         \includegraphics[width=\textwidth]{figures/supp/wv_squarelin_noise_filtered_NINO.pdf}
%       \end{subfigure}
%       \begin{subfigure}[b]{0.32\textwidth}
%         \includegraphics[width=\textwidth]{figures/supp/wv_squarelin_noise_filtered_NIFO.pdf}
%       \end{subfigure}
%       \captionof{figure}{Results on VW linear decision boundary data with varying noise levels. \mtl uses filtered triplets.}
%       \label{fig:lin-noise-filtered}
%   \end{minipage}
% \end{table}


% \begin{table}[t]
%   \begin{minipage}[b]{\textwidth}
%     \centering
%     \begin{subfigure}[b]{0.32\textwidth}
%       \includegraphics[width=\textwidth]{figures/supp/wv_squarelin_noise_unfiltered_h2h.pdf}
%       \end{subfigure}
%       \begin{subfigure}[b]{0.32\textwidth}
%         \includegraphics[width=\textwidth]{figures/supp/wv_squarelin_noise_unfiltered_NINO.pdf}
%       \end{subfigure}
%       \begin{subfigure}[b]{0.32\textwidth}
%         \includegraphics[width=\textwidth]{figures/supp/wv_squarelin_noise_unfiltered_NIFO.pdf}
%       \end{subfigure}
%       \captionof{figure}{Results on VW linear decision boundary data with varying noise levels. \mtl uses unfiltered triplets.}
%       \label{fig:lin-noise-unfiltered}
%   \end{minipage}
% \end{table}



% \begin{table}[t]
%   \begin{minipage}[b]{\textwidth}
%     \centering
%     \begin{subfigure}[b]{0.32\textwidth}
%       \includegraphics[width=\textwidth]{figures/supp/wv_squarelin_num_h2h.pdf}
%       \end{subfigure}
%       \begin{subfigure}[b]{0.32\textwidth}
%         \includegraphics[width=\textwidth]{figures/supp/wv_squarelin_num_NINO.pdf}
%       \end{subfigure}
%       \begin{subfigure}[b]{0.32\textwidth}
%         \includegraphics[width=\textwidth]{figures/supp/wv_squarelin_num_NIFO.pdf}
%       \end{subfigure}
%       \captionof{figure}{Results on VW linear decision boundary data with varying number of triplets. \mtl uses filtered triplets.}
%       \label{fig:lin-num}
%   \end{minipage}
% \end{table}