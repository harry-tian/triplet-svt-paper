%!TEX root = main.tex

\begin{abstract}
    Algorithmic case-based decision support provides examples to help human make sense of predicted labels and aid human in decision-making tasks. Despite the promising performance of supervised learning, representations learned by supervised models may not align well with human intuitions: what models consider as similar examples can be perceived as distinct by humans.
    As a result, they have limited effectiveness in case-based decision support.
    In this work, we incorporate ideas from metric learning with supervised learning to examine the importance of alignment for effective decision support.
    In addition to instance-level labels, we use human-provided triplet judgments to learn human-compatible decision-focused representation.
    Using both synthetic data and human subject experiments, we demonstrate that such representation is better aligned with human perception than representation solely optimized for classification.
    Human-compatible representations identify nearest neighbors that are perceived as more similar by humans and allow humans to make more accurate predictions.
\end{abstract}
